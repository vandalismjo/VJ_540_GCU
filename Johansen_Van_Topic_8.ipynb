{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This assignment is a bit different. One of the key expectations from any published article is reproducibility of results, especially in data science. In the last assignment in this course, you are tasked with attempting to reproduce the study described in a peer-reviewed article, published by the National Institute of Health (nih.gov). This tasked is aimed at gradually building your capacity to tackle complex topics, familiarize yourself with academic discourse, and provide context and practice for the skills you will eventually need when working on your capstone thesis or project.\n",
    "\n",
    "#### Ensemble-Based Classifier\n",
    "\n",
    "Familiarize yourself with the ensemble package in Python and its use in a Jupyter notebook by utilizing the “Ensemble Methods for Classification of Physical Activities” to complete this assignment. \n",
    "\n",
    "Note the additional digital resources in Supplemental Digital Content at the bottom of the article. Also, note that the dataset used in the article is available for download from the UCI repository and the direct link is included in the article in the Methods section, Data set 1.\n",
    "\n",
    "Another useful resource is “A Comprehensive Guide to Ensemble Learning (with Python codes).”\n",
    "\n",
    "Once you have reviewed the required resources, complete the following:\n",
    "\n",
    "Follow the steps described in the article for acquiring the data and building a classifier (in Python) that implements an ensemble framework. It is expected that you will encounter obstacles along the way and not every step mentioned in the article will be straightforward to implement. Ideally, you will be able to reproduce the project in its entirety. Less than ideal, but still very useful, would be to attempt most steps, adapt some, maybe eliminate one or two classification methods from the ensemble, but still produce a working classifier. Given the breadth and depth of the projects you worked on in this course and given the detailed resources provided that cover both theory and implementation, you are expected to successfully complete this project.\n",
    "\n",
    "In the event that you are able to fully implement the steps described in the article, it would make an excellent opportunity to write a paper informing the scientific community (and the authors) that you are corroborating the results. If you followed the steps to the letter, it would be even more interesting if you obtained a different result. In such case, the scientific community should hear from you.\n",
    "\n",
    "Create a technical report (no need to rewrite the article), in which you document your work, all steps, including the code and its output. Compare the results to the ones in the article, even if your ensemble framework is not identical to the one described in the article.\n",
    "\n",
    "APA style is expected, as well as formal and rigorous scientific writing, using appropriate mathematical notation and references.\n",
    "\n",
    "This assignment uses a rubric. Review the rubric prior to beginning the assignment to become familiar with the expectations for successful completion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attribute Information:\n",
    "\n",
    "##### The 54 columns in the data files are organized as follows:\n",
    "\n",
    "1 timestamp (s)\n",
    "\n",
    "2 activityID (see below for the mapping to the activities)\n",
    "\n",
    "3 heart rate (bpm)\n",
    "\n",
    "4-20. IMU hand\n",
    "\n",
    "21-37. IMU chest\n",
    "\n",
    "38-54. IMU ankle\n",
    "\n",
    "\n",
    "##### The IMU sensory data contains the following columns:\n",
    "\n",
    "1 temperature (Â°C)\n",
    "\n",
    "2-4. 3D-acceleration data (ms-2), scale: Â±16g, resolution: 13-bit\n",
    "\n",
    "5-7. 3D-acceleration data (ms-2), scale: Â±6g, resolution: 13-bit\n",
    "\n",
    "8-10. 3D-gyroscope data (rad/s)\n",
    "\n",
    "11-13. 3D-magnetometer data (Î¼T)\n",
    "\n",
    "14-17. orientation (invalid in this data collection)\n",
    "\n",
    "\n",
    "##### List of activityIDs and corresponding activities:\n",
    "\n",
    "1 lying\n",
    "\n",
    "2 sitting\n",
    "\n",
    "3 standing\n",
    "\n",
    "4 walking\n",
    "\n",
    "5 running\n",
    "\n",
    "6 cycling\n",
    "\n",
    "7 Nordic walking\n",
    "\n",
    "9 watching TV\n",
    "\n",
    "10 computer work\n",
    "\n",
    "11 car driving\n",
    "\n",
    "12 ascending stairs\n",
    "\n",
    "13 descending stairs\n",
    "\n",
    "16 vacuum cleaning\n",
    "\n",
    "17 ironing\n",
    "\n",
    "18 folding laundry\n",
    "\n",
    "19 house cleaning\n",
    "\n",
    "20 playing soccer\n",
    "\n",
    "24 rope jumping\n",
    "\n",
    "0 other (transient activities)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.preprocessing import normalize\n",
    "import xgboost as xgb\n",
    "from scipy.stats import uniform, randint\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import auc, accuracy_score, confusion_matrix, mean_squared_error, roc_auc_score, plot_roc_curve, roc_curve\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, BaggingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>8.38</th>\n",
       "      <th>0</th>\n",
       "      <th>104</th>\n",
       "      <th>30</th>\n",
       "      <th>2.37223</th>\n",
       "      <th>8.60074</th>\n",
       "      <th>3.51048</th>\n",
       "      <th>2.43954</th>\n",
       "      <th>8.76165</th>\n",
       "      <th>3.35465</th>\n",
       "      <th>...</th>\n",
       "      <th>0.00830026</th>\n",
       "      <th>0.00925038</th>\n",
       "      <th>-0.0175803</th>\n",
       "      <th>-61.1888</th>\n",
       "      <th>-38.9599</th>\n",
       "      <th>-58.1438</th>\n",
       "      <th>1.2</th>\n",
       "      <th>0.7</th>\n",
       "      <th>0.8</th>\n",
       "      <th>0.9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.39</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2.18837</td>\n",
       "      <td>8.56560</td>\n",
       "      <td>3.66179</td>\n",
       "      <td>2.39494</td>\n",
       "      <td>8.55081</td>\n",
       "      <td>3.64207</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006577</td>\n",
       "      <td>-0.004638</td>\n",
       "      <td>0.000368</td>\n",
       "      <td>-59.8479</td>\n",
       "      <td>-38.8919</td>\n",
       "      <td>-58.5253</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.40</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2.37357</td>\n",
       "      <td>8.60107</td>\n",
       "      <td>3.54898</td>\n",
       "      <td>2.30514</td>\n",
       "      <td>8.53644</td>\n",
       "      <td>3.73280</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003014</td>\n",
       "      <td>0.000148</td>\n",
       "      <td>0.022495</td>\n",
       "      <td>-60.7361</td>\n",
       "      <td>-39.4138</td>\n",
       "      <td>-58.3999</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.41</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2.07473</td>\n",
       "      <td>8.52853</td>\n",
       "      <td>3.66021</td>\n",
       "      <td>2.33528</td>\n",
       "      <td>8.53622</td>\n",
       "      <td>3.73277</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003175</td>\n",
       "      <td>-0.020301</td>\n",
       "      <td>0.011275</td>\n",
       "      <td>-60.4091</td>\n",
       "      <td>-38.7635</td>\n",
       "      <td>-58.3956</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.42</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2.22936</td>\n",
       "      <td>8.83122</td>\n",
       "      <td>3.70000</td>\n",
       "      <td>2.23055</td>\n",
       "      <td>8.59741</td>\n",
       "      <td>3.76295</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012698</td>\n",
       "      <td>-0.014303</td>\n",
       "      <td>-0.002823</td>\n",
       "      <td>-61.5199</td>\n",
       "      <td>-39.3879</td>\n",
       "      <td>-58.2694</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.43</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2.29959</td>\n",
       "      <td>8.82929</td>\n",
       "      <td>3.54710</td>\n",
       "      <td>2.26132</td>\n",
       "      <td>8.65762</td>\n",
       "      <td>3.77788</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006089</td>\n",
       "      <td>-0.016024</td>\n",
       "      <td>0.001050</td>\n",
       "      <td>-60.2954</td>\n",
       "      <td>-38.8778</td>\n",
       "      <td>-58.3977</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   8.38  0  104    30  2.37223  8.60074  3.51048  2.43954  8.76165  3.35465  \\\n",
       "0  8.39  0  NaN  30.0  2.18837  8.56560  3.66179  2.39494  8.55081  3.64207   \n",
       "1  8.40  0  NaN  30.0  2.37357  8.60107  3.54898  2.30514  8.53644  3.73280   \n",
       "2  8.41  0  NaN  30.0  2.07473  8.52853  3.66021  2.33528  8.53622  3.73277   \n",
       "3  8.42  0  NaN  30.0  2.22936  8.83122  3.70000  2.23055  8.59741  3.76295   \n",
       "4  8.43  0  NaN  30.0  2.29959  8.82929  3.54710  2.26132  8.65762  3.77788   \n",
       "\n",
       "   ...  0.00830026  0.00925038  -0.0175803  -61.1888  -38.9599  -58.1438  1.2  \\\n",
       "0  ...   -0.006577   -0.004638    0.000368  -59.8479  -38.8919  -58.5253  1.0   \n",
       "1  ...    0.003014    0.000148    0.022495  -60.7361  -39.4138  -58.3999  1.0   \n",
       "2  ...    0.003175   -0.020301    0.011275  -60.4091  -38.7635  -58.3956  1.0   \n",
       "3  ...    0.012698   -0.014303   -0.002823  -61.5199  -39.3879  -58.2694  1.0   \n",
       "4  ...   -0.006089   -0.016024    0.001050  -60.2954  -38.8778  -58.3977  1.0   \n",
       "\n",
       "   0.7  0.8  0.9  \n",
       "0  0.0  0.0  0.0  \n",
       "1  0.0  0.0  0.0  \n",
       "2  0.0  0.0  0.0  \n",
       "3  0.0  0.0  0.0  \n",
       "4  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 54 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_table(\"protocol/subject101.dat\", sep=\" \", header=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df.iloc[:,[0,1,2,3,20,37]]\n",
    "df_clean.columns = ['timestamp', 'activityID', 'heart_rate1', 'IMU_hand1', 'IMU_chest1', 'IMU_ankle1']\n",
    "df_clean.head()\n",
    "df_clean = df_clean.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9         other\n",
       "20        other\n",
       "31        other\n",
       "42        other\n",
       "53        other\n",
       "          ...  \n",
       "376364    other\n",
       "376375    other\n",
       "376386    other\n",
       "376397    other\n",
       "376408    other\n",
       "Name: activityID, Length: 34089, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act_dict = {1: 'lying', 2: 'sitting',3: 'standing',4: 'walking',5: 'running',6: 'cycling',7: 'Nordic_walking',9: 'watching_TV',\n",
    "            10: 'computer_work',11: 'car_driving',12: 'ascending_stairs',13: 'descending_stairs',16: 'vacuum_cleaning',17: 'ironing',\n",
    "            18: 'folding_laundry',19: 'house_cleaning',20: 'playing_soccer',24: 'rope_jumping',0: 'other'}\n",
    "df_clean['activityID'].map(act_dict)\n",
    "df_clean1 = df_clean.copy()\n",
    "df_clean1['activityID'].map(act_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df_clean, random_state=6)\n",
    "\n",
    "X_train = normalize(train.drop([\"heart_rate1\"], axis=1))\n",
    "X_test = normalize(test.drop([\"heart_rate1\"], axis=1))\n",
    "\n",
    "y_train = train.heart_rate1\n",
    "y_test = test.heart_rate1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### After the preprocessing, start with simple models like random forest and boosting. Run the random forest with the same number of trees as the study - 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01032500293323947"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=20)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 200 candidates, totalling 600 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   11.6s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   55.8s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 600 out of 600 | elapsed:  2.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9994842293757199"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model = xgb.XGBRegressor(random_state=6)\n",
    "\n",
    "params = {\n",
    "  \"colsample_bytree\": uniform(0.7, 0.3),\n",
    "  \"gamma\": uniform(0, 0.5),\n",
    "  \"learning_rate\": uniform(0.03, 0.3), # default 0.1 \n",
    "  \"max_depth\": randint(2, 6), # default 3\n",
    "  \"n_estimators\": randint(100, 150), # default 100\n",
    "  \"subsample\": uniform(0.6, 0.4)\n",
    "}\n",
    "\n",
    "#use gridsearch to test all values for hyperparams\n",
    "xgbcv = RandomizedSearchCV(xgb_model, param_distributions=params, random_state=6, n_iter=200, cv=3, verbose=1, \n",
    "                           n_jobs=-1, return_train_score=True)\n",
    "#fit model to training data\n",
    "xgbcv.fit(X_train, y_train)\n",
    "\n",
    "predictions_test = xgbcv.predict(X_test)\n",
    "\n",
    "xgbcv.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### After initial investigation compare to an ansemble model made up of different model types in this instance knn, random forest and logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': 1}\n",
      "{'n_estimators': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zzenz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knn: 0.9529508389064884\n",
      "rf: 0.9504869177519653\n",
      "log_reg: 0.06863780359028511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zzenz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.944385779655051"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create new a knn model\n",
    "knn = KNeighborsClassifier()\n",
    "#create a dictionary of all values we want to test for n_neighbors\n",
    "params_knn = {'n_neighbors': np.arange(1, 25)}\n",
    "#use gridsearch to test all values for n_neighbors\n",
    "knn_gs = GridSearchCV(knn, params_knn, cv=5)\n",
    "#fit model to training data\n",
    "knn_gs.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "#save best model\n",
    "knn_best = knn_gs.best_estimator_\n",
    "#check best n_neigbors value\n",
    "print(knn_gs.best_params_)\n",
    "\n",
    "\n",
    "\n",
    "#create a new random forest classifier\n",
    "rf = RandomForestClassifier()\n",
    "#create a dictionary of all values we want to test for n_estimators\n",
    "params_rf = {'n_estimators': [50, 100, 200]}\n",
    "#use gridsearch to test all values for n_estimators\n",
    "rf_gs = GridSearchCV(rf, params_rf, cv=5)\n",
    "#fit model to training data\n",
    "rf_gs.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "#save best model\n",
    "rf_best = rf_gs.best_estimator_\n",
    "#check best n_estimators value\n",
    "print(rf_gs.best_params_)\n",
    "\n",
    "\n",
    "#create a new logistic regression model\n",
    "log_reg = LogisticRegression()\n",
    "#fit the model to the training data\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "#test the three models with the test data and print their accuracy scores\n",
    "print('knn: {}'.format(knn_best.score(X_test, y_test)))\n",
    "print('rf: {}'.format(rf_best.score(X_test, y_test)))\n",
    "print('log_reg: {}'.format(log_reg.score(X_test, y_test)))\n",
    "\n",
    "\n",
    "#create a dictionary of our models\n",
    "estimators=[('knn', knn_best), ('rf', rf_best), ('log_reg', log_reg)]\n",
    "#create our voting classifier, inputting our models\n",
    "ensemble = VotingClassifier(estimators, voting='hard')\n",
    "\n",
    "#fit model to training data\n",
    "ensemble.fit(X_train, y_train)\n",
    "#test our model on the test data\n",
    "ensemble.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
